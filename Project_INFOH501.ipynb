{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlab_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CIFAR10, get_hog_image\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load Dataset\u001b[39;00m\n\u001b[0;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CIFAR10(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCIFAR10/CIFAR10/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\info-h-501\\docs\\LABS\\lab_tools.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from lab_tools import CIFAR10, get_hog_image\n",
    "\n",
    "# Load Dataset\n",
    "dataset = CIFAR10('CIFAR10/CIFAR10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlab_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CIFAR10, get_hog_image\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix\n",
      "File \u001b[1;32m~\\info-h-501\\docs\\LABS\\lab_tools.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from lab_tools import CIFAR10, get_hog_image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Load Dataset\n",
    "dataset = CIFAR10('CIFAR10/CIFAR10/')\n",
    "\n",
    "# 1. Fraction of data for validation\n",
    "p_val = 0.1\n",
    "n_val = int(p_val * len(dataset.train['hog']))\n",
    "\n",
    "# 2. Training and Validation Split\n",
    "train_X = dataset.train['hog'][:-n_val]\n",
    "train_Y = dataset.train['labels'][:-n_val]\n",
    "\n",
    "val_X = dataset.train['hog'][-n_val:]\n",
    "val_Y = dataset.train['labels'][-n_val:]\n",
    "\n",
    "print(train_X.shape, train_Y.shape, val_X.shape, val_Y.shape)\n",
    "\n",
    "# Descriptive Performance\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(train_X, train_Y)\n",
    "pred_descr = clf.predict(train_X)\n",
    "descriptive_score = accuracy_score(train_Y, pred_descr)\n",
    "print(f\"Descriptive Score: {descriptive_score:.3f}\")\n",
    "\n",
    "# Predictive Performance using Cross-Validation\n",
    "k_values = [1, 3, 4, 5, 6, 7, 9]\n",
    "cv_scores = []\n",
    "for k in k_values:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(clf, train_X, train_Y, cv=10)\n",
    "    cv_scores.append(scores.mean())\n",
    "    print(f\"K={k}, Cross-Validation Score: {scores.mean():.3f}\")\n",
    "\n",
    "# Best K based on Cross-Validation\n",
    "best_k_index = np.argmax(cv_scores)\n",
    "best_k = k_values[best_k_index]\n",
    "print(f\"Best K based on Cross-Validation: {best_k}\")\n",
    "\n",
    "# Final Predictive Score using Best K\n",
    "clf = KNeighborsClassifier(n_neighbors=best_k)\n",
    "clf.fit(train_X, train_Y)\n",
    "pred = clf.predict(val_X)\n",
    "final_score = accuracy_score(val_Y, pred)\n",
    "print(f\"Predictive Score using Best K: {final_score:.3f}\")\n",
    "\n",
    "# Confusion Matrix for Best K\n",
    "cm = confusion_matrix(val_Y, pred)\n",
    "print(\"Confusion Matrix for Best K:\\n\", cm)\n",
    "print(\"Sum by Class:\", cm.sum(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-loading training data\n",
      "Pre-loading test data\n",
      "(13500, 256) (13500,) (1500, 256) (1500,)\n",
      "Descriptive Score: 0.805\n",
      "\n",
      "Metric: euclidean\n",
      "K=1, Cross-Validation Score: 0.683\n",
      "K=3, Cross-Validation Score: 0.700\n",
      "K=5, Cross-Validation Score: 0.704\n",
      "K=7, Cross-Validation Score: 0.701\n",
      "K=9, Cross-Validation Score: 0.699\n",
      "Best K for euclidean: 5\n",
      "Predictive Score using Best K (euclidean): 0.713\n",
      "Confusion Matrix for Best K ({metric}):\n",
      " [[330 129  53]\n",
      " [ 35 388  67]\n",
      " [ 15 131 352]]\n",
      "Sum by Class: [512 490 498]\n",
      "\n",
      "Metric: manhattan\n",
      "K=1, Cross-Validation Score: 0.741\n",
      "K=3, Cross-Validation Score: 0.762\n",
      "K=5, Cross-Validation Score: 0.770\n",
      "K=7, Cross-Validation Score: 0.768\n",
      "K=9, Cross-Validation Score: 0.768\n",
      "Best K for manhattan: 5\n",
      "Predictive Score using Best K (manhattan): 0.769\n",
      "Confusion Matrix for Best K ({metric}):\n",
      " [[393  89  30]\n",
      " [ 42 390  58]\n",
      " [ 15 112 371]]\n",
      "Sum by Class: [512 490 498]\n",
      "\n",
      "Metric: chebyshev\n",
      "K=1, Cross-Validation Score: 0.589\n",
      "K=3, Cross-Validation Score: 0.615\n",
      "K=5, Cross-Validation Score: 0.627\n",
      "K=7, Cross-Validation Score: 0.628\n",
      "K=9, Cross-Validation Score: 0.632\n",
      "Best K for chebyshev: 9\n",
      "Predictive Score using Best K (chebyshev): 0.639\n",
      "Confusion Matrix for Best K ({metric}):\n",
      " [[292 107 113]\n",
      " [ 59 293 138]\n",
      " [ 17 107 374]]\n",
      "Sum by Class: [512 490 498]\n"
     ]
    }
   ],
   "source": [
    "from lab_tools import CIFAR10, get_hog_image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Load Dataset\n",
    "dataset = CIFAR10('CIFAR10/CIFAR10/')\n",
    "\n",
    "# 1. Fraction of data for validation\n",
    "p_val = 0.1\n",
    "n_val = int(p_val * len(dataset.train['hog']))\n",
    "\n",
    "# 2. Training and Validation Split\n",
    "train_X = dataset.train['hog'][:-n_val]\n",
    "train_Y = dataset.train['labels'][:-n_val]\n",
    "\n",
    "val_X = dataset.train['hog'][-n_val:]\n",
    "val_Y = dataset.train['labels'][-n_val:]\n",
    "\n",
    "print(train_X.shape, train_Y.shape, val_X.shape, val_Y.shape)\n",
    "\n",
    "# Descriptive Performance\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(train_X, train_Y)\n",
    "pred_descr = clf.predict(train_X)\n",
    "descriptive_score = accuracy_score(train_Y, pred_descr)\n",
    "print(f\"Descriptive Score: {descriptive_score:.3f}\")\n",
    "\n",
    "# Predictive Performance using Stratified Cross-Validation and Different Metrics\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "metrics = ['euclidean', 'manhattan', 'chebyshev']\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\nMetric: {metric}\")\n",
    "    cv_scores = []\n",
    "    for k in k_values:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "        scores = cross_val_score(clf, train_X, train_Y, cv=skf)\n",
    "        cv_scores.append(scores.mean())\n",
    "        print(f\"K={k}, Cross-Validation Score: {scores.mean():.3f}\")\n",
    "\n",
    "    # Best K based on Cross-Validation for this metric\n",
    "    best_k_index = np.argmax(cv_scores)\n",
    "    best_k = k_values[best_k_index]\n",
    "    print(f\"Best K for {metric}: {best_k}\")\n",
    "\n",
    "    # Final Predictive Score using Best K for this metric\n",
    "    clf = KNeighborsClassifier(n_neighbors=best_k, metric=metric)\n",
    "    clf.fit(train_X, train_Y)\n",
    "    pred = clf.predict(val_X)\n",
    "    final_score = accuracy_score(val_Y, pred)\n",
    "    print(f\"Predictive Score using Best K ({metric}): {final_score:.3f}\")\n",
    "\n",
    "    # Confusion Matrix for Best K and Metric\n",
    "    cm = confusion_matrix(val_Y, pred)\n",
    "    print(\"Confusion Matrix for Best K ({metric}):\\n\", cm)\n",
    "    print(\"Sum by Class:\", cm.sum(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-loading training data\n",
      "Pre-loading test data\n",
      "(13500, 256) (13500,) (1500, 256) (1500,)\n",
      "Descriptive Score (Original): 0.805\n",
      "\n",
      "Metric: euclidean\n",
      "\n",
      "Data: Original\n",
      "K=1, Cross-Validation Score: 0.683\n",
      "K=3, Cross-Validation Score: 0.700\n",
      "K=5, Cross-Validation Score: 0.704\n",
      "K=7, Cross-Validation Score: 0.701\n",
      "K=9, Cross-Validation Score: 0.699\n",
      "Best K for euclidean (Original): 5\n",
      "Predictive Score using Best K (euclidean, Original): 0.713\n",
      "Confusion Matrix for Best K ({metric}, {data}):\n",
      " [[330 129  53]\n",
      " [ 35 388  67]\n",
      " [ 15 131 352]]\n",
      "Sum by Class: [512 490 498]\n",
      "\n",
      "Data: Normalized\n",
      "K=1, Cross-Validation Score: 0.683\n",
      "K=3, Cross-Validation Score: 0.708\n",
      "K=5, Cross-Validation Score: 0.716\n",
      "K=7, Cross-Validation Score: 0.713\n",
      "K=9, Cross-Validation Score: 0.714\n",
      "Best K for euclidean (Normalized): 5\n",
      "Predictive Score using Best K (euclidean, Normalized): 0.729\n",
      "Confusion Matrix for Best K ({metric}, {data}):\n",
      " [[352 120  40]\n",
      " [ 43 378  69]\n",
      " [ 16 119 363]]\n",
      "Sum by Class: [512 490 498]\n",
      "\n",
      "Data: PCA\n",
      "K=1, Cross-Validation Score: 0.690\n",
      "K=3, Cross-Validation Score: 0.715\n",
      "K=5, Cross-Validation Score: 0.720\n",
      "K=7, Cross-Validation Score: 0.721\n",
      "K=9, Cross-Validation Score: 0.718\n",
      "Best K for euclidean (PCA): 7\n",
      "Predictive Score using Best K (euclidean, PCA): 0.738\n",
      "Confusion Matrix for Best K ({metric}, {data}):\n",
      " [[351 106  55]\n",
      " [ 33 386  71]\n",
      " [  9 119 370]]\n",
      "Sum by Class: [512 490 498]\n",
      "\n",
      "Metric: manhattan\n",
      "\n",
      "Data: Original\n",
      "K=1, Cross-Validation Score: 0.741\n",
      "K=3, Cross-Validation Score: 0.762\n",
      "K=5, Cross-Validation Score: 0.770\n",
      "K=7, Cross-Validation Score: 0.768\n",
      "K=9, Cross-Validation Score: 0.768\n",
      "Best K for manhattan (Original): 5\n",
      "Predictive Score using Best K (manhattan, Original): 0.769\n",
      "Confusion Matrix for Best K ({metric}, {data}):\n",
      " [[393  89  30]\n",
      " [ 42 390  58]\n",
      " [ 15 112 371]]\n",
      "Sum by Class: [512 490 498]\n",
      "\n",
      "Data: Normalized\n",
      "K=1, Cross-Validation Score: 0.748\n",
      "K=3, Cross-Validation Score: 0.771\n",
      "K=5, Cross-Validation Score: 0.785\n",
      "K=7, Cross-Validation Score: 0.781\n",
      "K=9, Cross-Validation Score: 0.783\n",
      "Best K for manhattan (Normalized): 5\n",
      "Predictive Score using Best K (manhattan, Normalized): 0.780\n",
      "Confusion Matrix for Best K ({metric}, {data}):\n",
      " [[418  72  22]\n",
      " [ 56 371  63]\n",
      " [ 15 102 381]]\n",
      "Sum by Class: [512 490 498]\n",
      "\n",
      "Data: PCA\n",
      "K=1, Cross-Validation Score: 0.647\n",
      "K=3, Cross-Validation Score: 0.670\n",
      "K=5, Cross-Validation Score: 0.678\n",
      "K=7, Cross-Validation Score: 0.681\n",
      "K=9, Cross-Validation Score: 0.680\n",
      "Best K for manhattan (PCA): 7\n",
      "Predictive Score using Best K (manhattan, PCA): 0.681\n",
      "Confusion Matrix for Best K ({metric}, {data}):\n",
      " [[315 131  66]\n",
      " [ 28 372  90]\n",
      " [ 13 150 335]]\n",
      "Sum by Class: [512 490 498]\n",
      "\n",
      "Metric: chebyshev\n",
      "\n",
      "Data: Original\n",
      "K=1, Cross-Validation Score: 0.589\n",
      "K=3, Cross-Validation Score: 0.615\n",
      "K=5, Cross-Validation Score: 0.627\n",
      "K=7, Cross-Validation Score: 0.628\n",
      "K=9, Cross-Validation Score: 0.632\n",
      "Best K for chebyshev (Original): 9\n",
      "Predictive Score using Best K (chebyshev, Original): 0.639\n",
      "Confusion Matrix for Best K ({metric}, {data}):\n",
      " [[292 107 113]\n",
      " [ 59 293 138]\n",
      " [ 17 107 374]]\n",
      "Sum by Class: [512 490 498]\n",
      "\n",
      "Data: Normalized\n",
      "K=1, Cross-Validation Score: 0.558\n",
      "K=3, Cross-Validation Score: 0.581\n",
      "K=5, Cross-Validation Score: 0.596\n",
      "K=7, Cross-Validation Score: 0.597\n",
      "K=9, Cross-Validation Score: 0.601\n",
      "Best K for chebyshev (Normalized): 9\n",
      "Predictive Score using Best K (chebyshev, Normalized): 0.610\n",
      "Confusion Matrix for Best K ({metric}, {data}):\n",
      " [[275 123 114]\n",
      " [ 54 281 155]\n",
      " [ 19 120 359]]\n",
      "Sum by Class: [512 490 498]\n",
      "\n",
      "Data: PCA\n",
      "K=1, Cross-Validation Score: 0.678\n",
      "K=3, Cross-Validation Score: 0.699\n",
      "K=5, Cross-Validation Score: 0.714\n",
      "K=7, Cross-Validation Score: 0.715\n",
      "K=9, Cross-Validation Score: 0.719\n",
      "Best K for chebyshev (PCA): 9\n",
      "Predictive Score using Best K (chebyshev, PCA): 0.724\n",
      "Confusion Matrix for Best K ({metric}, {data}):\n",
      " [[359 102  51]\n",
      " [ 51 337 102]\n",
      " [  8 100 390]]\n",
      "Sum by Class: [512 490 498]\n"
     ]
    }
   ],
   "source": [
    "from lab_tools import CIFAR10, get_hog_image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Load Dataset\n",
    "dataset = CIFAR10('CIFAR10/CIFAR10/')\n",
    "\n",
    "# 1. Fraction of data for validation\n",
    "p_val = 0.1\n",
    "n_val = int(p_val * len(dataset.train['hog']))\n",
    "\n",
    "# 2. Training and Validation Split\n",
    "train_X = dataset.train['hog'][:-n_val]\n",
    "train_Y = dataset.train['labels'][:-n_val]\n",
    "\n",
    "val_X = dataset.train['hog'][-n_val:]\n",
    "val_Y = dataset.train['labels'][-n_val:]\n",
    "\n",
    "print(train_X.shape, train_Y.shape, val_X.shape, val_Y.shape)\n",
    "\n",
    "# Preprocessing: Normalization\n",
    "scaler = StandardScaler()\n",
    "train_X_norm = scaler.fit_transform(train_X)\n",
    "val_X_norm = scaler.transform(val_X)\n",
    "\n",
    "# Preprocessing: PCA (95% Variance Retention)\n",
    "pca = PCA(n_components=0.95)\n",
    "train_X_pca = pca.fit_transform(train_X_norm)\n",
    "val_X_pca = pca.transform(val_X_norm)\n",
    "\n",
    "# Descriptive Performance - Original\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(train_X, train_Y)\n",
    "pred_descr = clf.predict(train_X)\n",
    "descriptive_score = accuracy_score(train_Y, pred_descr)\n",
    "print(f\"Descriptive Score (Original): {descriptive_score:.3f}\")\n",
    "\n",
    "# Predictive Performance using Stratified Cross-Validation and Different Metrics\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "metrics = ['euclidean', 'manhattan', 'chebyshev']\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\nMetric: {metric}\")\n",
    "    for data, label in zip(['Original', 'Normalized', 'PCA'], [train_X, train_X_norm, train_X_pca]):\n",
    "        print(f\"\\nData: {data}\")\n",
    "        cv_scores = []\n",
    "        for k in k_values:\n",
    "            clf = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "            scores = cross_val_score(clf, label, train_Y, cv=skf)\n",
    "            cv_scores.append(scores.mean())\n",
    "            print(f\"K={k}, Cross-Validation Score: {scores.mean():.3f}\")\n",
    "\n",
    "        # Best K based on Cross-Validation for this metric and data\n",
    "        best_k_index = np.argmax(cv_scores)\n",
    "        best_k = k_values[best_k_index]\n",
    "        print(f\"Best K for {metric} ({data}): {best_k}\")\n",
    "\n",
    "        # Final Predictive Score using Best K\n",
    "        clf = KNeighborsClassifier(n_neighbors=best_k, metric=metric)\n",
    "        clf.fit(label, train_Y)\n",
    "        if data == 'Original':\n",
    "            pred = clf.predict(val_X)\n",
    "        elif data == 'Normalized':\n",
    "            pred = clf.predict(val_X_norm)\n",
    "        else:\n",
    "            pred = clf.predict(val_X_pca)\n",
    "\n",
    "        final_score = accuracy_score(val_Y, pred)\n",
    "        print(f\"Predictive Score using Best K ({metric}, {data}): {final_score:.3f}\")\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(val_Y, pred)\n",
    "        print(\"Confusion Matrix for Best K ({metric}, {data}):\\n\", cm)\n",
    "        print(\"Sum by Class:\", cm.sum(axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-loading training data\n",
      "Pre-loading test data\n",
      "(13500, 256) (13500,) (1500, 256) (1500,)\n",
      "Descriptive Score (Decision Tree): 1.000\n",
      "Max Depth=5, Cross-Validation Score: 0.578\n",
      "Max Depth=10, Cross-Validation Score: 0.593\n",
      "Max Depth=15, Cross-Validation Score: 0.582\n",
      "Max Depth=20, Cross-Validation Score: 0.573\n",
      "Max Depth=None, Cross-Validation Score: 0.570\n",
      "Best Max Depth based on Cross-Validation: 10\n",
      "Predictive Score using Best Max Depth: 0.604\n",
      "Confusion Matrix for Best Max Depth:\n",
      " [[325 122  65]\n",
      " [ 91 307  92]\n",
      " [ 62 162 274]]\n",
      "Sum by Class: [512 490 498]\n"
     ]
    }
   ],
   "source": [
    "from lab_tools import CIFAR10, get_hog_image\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Load Dataset\n",
    "dataset = CIFAR10('CIFAR10/CIFAR10/')\n",
    "\n",
    "# 1. Fraction of data for validation\n",
    "p_val = 0.1\n",
    "n_val = int(p_val * len(dataset.train['hog']))\n",
    "\n",
    "# 2. Training and Validation Split\n",
    "train_X = dataset.train['hog'][:-n_val]\n",
    "train_Y = dataset.train['labels'][:-n_val]\n",
    "\n",
    "val_X = dataset.train['hog'][-n_val:]\n",
    "val_Y = dataset.train['labels'][-n_val:]\n",
    "\n",
    "print(train_X.shape, train_Y.shape, val_X.shape, val_Y.shape)\n",
    "\n",
    "# Descriptive Performance - Decision Tree\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(train_X, train_Y)\n",
    "pred_descr = clf.predict(train_X)\n",
    "descriptive_score = accuracy_score(train_Y, pred_descr)\n",
    "print(f\"Descriptive Score (Decision Tree): {descriptive_score:.3f}\")\n",
    "\n",
    "# Predictive Performance using Stratified Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "max_depth_values = [5, 10, 15, 20, None]\n",
    "cv_scores = []\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    scores = cross_val_score(clf, train_X, train_Y, cv=skf)\n",
    "    cv_scores.append(scores.mean())\n",
    "    print(f\"Max Depth={depth}, Cross-Validation Score: {scores.mean():.3f}\")\n",
    "\n",
    "# Best Max Depth based on Cross-Validation\n",
    "best_depth_index = np.argmax(cv_scores)\n",
    "best_depth = max_depth_values[best_depth_index]\n",
    "print(f\"Best Max Depth based on Cross-Validation: {best_depth}\")\n",
    "\n",
    "# Final Predictive Score using Best Max Depth\n",
    "clf = DecisionTreeClassifier(max_depth=best_depth, random_state=42)\n",
    "clf.fit(train_X, train_Y)\n",
    "pred = clf.predict(val_X)\n",
    "final_score = accuracy_score(val_Y, pred)\n",
    "print(f\"Predictive Score using Best Max Depth: {final_score:.3f}\")\n",
    "\n",
    "# Confusion Matrix for Best Depth\n",
    "cm = confusion_matrix(val_Y, pred)\n",
    "print(\"Confusion Matrix for Best Max Depth:\\n\", cm)\n",
    "print(\"Sum by Class:\", cm.sum(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (infoh501)",
   "language": "python",
   "name": "infoh501"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
